#importing libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import accuracy_score

#import dataset
ds = pd.read_csv('C:/Users/user/Documents/MSDS/Semester II/Practice datasets/DM_dataset.csv')
print(ds.info())

#check for missing values
print(ds.isnull().sum())

#separating features and target variables
x = ds[['Gender', 'AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI']]
y = ds ['CLASS']

#remove leading spaces from y
y = y.astype(str).str.strip()

#encoding categorical variables
label_encoder=LabelEncoder()
for col in x.select_dtypes(include=['object']).columns:
    x.loc[:, col] = label_encoder.fit_transform(x[col])

#split data into training and testing set
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state = 42
)

#create the model
model = DecisionTreeClassifier(criterion='entropy', random_state=42)

#train the model
model.fit(x_train, y_train)

#predict using the test set
y_pred = model.predict(x_test)

#visualize the tree
plt.figure(figsize = (20,10))
plot_tree(model,
          feature_names = x.columns,
          class_names = model.classes_,
          filled = True,
          rounded = True,
          fontsize = 10)
plt.show()

#see feature importance
importances = model.feature_importances_
feature_ds = pd.DataFrame({
    'Feature': x.columns,
    'Importance': importances
}) #dataframe to see importance
feature_ds = feature_ds.sort_values(by='Importance', ascending = False) #sort by importance
print(feature_ds)

#plot feature importance alternative to print
sns.barplot(x = 'Importance', y = 'Feature', data=feature_ds)
plt.title('Feature Importance')
plt.tight_layout()
plt.show()

#evaluate performance
#Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))
#confusion matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
#classification report
print("\nClassification Report:")
print(classification_report(y_test,y_pred))

#accuracy on train and test set
#prediction on training set. dont need to predict the test set again
y_pred_train = model.predict(x_train)
#calculate accuracy on both sets
train_accuracy = accuracy_score(y_train, y_pred_train)
test_accuracy = accuracy_score(y_test, y_pred)
print (f"Training Accuracy: {train_accuracy:.4f}")
print (f"Test Accuracy: {test_accuracy:.4f}")

#post pruning
path = model.cost_complexity_pruning_path(x_train, y_train)
ccp_alphas = path.ccp_alphas
ccp_alphas = ccp_alphas[:-1]

clfs = [] #store pruned model here
train_scores = []
test_scores = []

for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha, random_state=42)
    clf.fit(x_train, y_train)
    y_train_pred = clf.predict(x_train)
    y_test_pred = clf.predict(x_test)
    clfs.append(clf)
    train_scores.append(accuracy_score(y_train, y_train_pred))
    test_scores.append(accuracy_score(y_test, y_test_pred))

#visualize pruning effect
plt.figure(figsize=(10,6))
plt.plot(ccp_alphas, train_scores, marker='o', label="Training Accuracy", drawstyle="steps-post")
plt.plot(ccp_alphas, test_scores, marker='o', label="Test Accuracy", drawstyle="steps-post")
plt.xlabel("ccp_alpha")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Accuracy vs ccp_alpha (Post-Pruning)")
plt.grid()
plt.show()

#find best accuracy alpha
best_index = test_scores.index(max(test_scores))
best_alpha = ccp_alphas[best_index]
best_accuracy = test_scores[best_index]
print(f"Best ccp_alpha: {best_alpha:.5f}")
print(f"Best Test Accuracy: {best_accuracy:.4f}")

#retrain using best alpha
final_model = DecisionTreeClassifier(ccp_alpha=best_alpha, criterion= 'entropy', random_state=42)
final_model.fit(x_train, y_train)

#pruned tree visualization
plt.figure(figsize=(20,10))
plot_tree(final_model,
          feature_names=x.columns,
          class_names=sorted(y.unique()),
          filled=True,
          rounded=True,
          fontsize=10,
         max_depth=3)
plt.title("Pruned Decision Tree")
plt.show()

#compare feature importance of original and pruned model
original_importances = model.feature_importances_
comparison_df = pd.DataFrame({
    'Feature': x.columns,
    'Original Importance': original_importances,
    'Pruned Importance': importances
})

# Sort by pruned importance
comparison_df = comparison_df.sort_values(by='Pruned Importance', ascending=False)
comparison_df.set_index('Feature').plot(kind='barh', figsize=(10,8))
plt.title('Feature Importance Comparison')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.legend(['Original', 'Pruned'])
plt.tight_layout()
plt.show()

#calculate pruned accuracy for test and train set
y_train_pred_pruned = final_model.predict(x_train)
y_test_pred_pruned = final_model.predict(x_test)
train_acc_pruned = accuracy_score(y_train, y_train_pred_pruned)
test_acc_pruned = accuracy_score(y_test, y_test_pred_pruned)

print(f"Pruned Model - Training Accuracy: {train_acc_pruned:.4f}")
print(f"Pruned Model - Test Accuracy:     {test_acc_pruned:.4f}")

# Compare Original and pruned tree accuracy
y_train_pred_orig = model.predict(x_train)
y_test_pred_orig = model.predict(x_test)

# Original accuracies
train_acc_orig = accuracy_score(y_train, y_train_pred_orig)
test_acc_orig = accuracy_score(y_test, y_test_pred_orig)
print(f"\n{'Model':<15} | {'Train Acc':<8} | {'Test Acc':<8}")
print("-"*40)
print(f"{'Original':<15} | {train_acc_orig:.4f}   | {test_acc_orig:.4f}")
print(f"{'Pruned':<15} | {train_acc_pruned:.4f}   | {test_acc_pruned:.4f}")
